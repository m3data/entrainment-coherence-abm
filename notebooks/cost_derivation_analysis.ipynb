{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Cost Derivation Analysis\n",
    "\n",
    "Deriving expected cost profiles from existing coherence model metrics.\n",
    "\n",
    "**Reference:** `notes/cost-types.md`\n",
    "\n",
    "## Cost Proxy Mapping\n",
    "\n",
    "| Cost Type | Proxy Metric | Interpretation |\n",
    "|-----------|--------------|----------------|\n",
    "| **Shock Cost** | `max_deviation` | How violently does the system absorb stress? |\n",
    "| **Repair Cost** | `recovery_time` | How long does the system remain impaired? |\n",
    "| **Maintenance Cost** | `baseline` variance | How much does the system pay to stay adaptable? |\n",
    "| **Cost Efficiency** | Amplification ratios | How efficiently does the system convert perturbation into damage? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "EXPORTS_DIR = Path('../exports')\n",
    "NOTES_DIR = Path('../notes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import parsing functions from main notebook\n",
    "def parse_behaviorspace_spreadsheet(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    metadata = {\n",
    "        'version': lines[0].strip().split(',')[0].strip('\"'),\n",
    "        'model': lines[1].strip().strip('\"'),\n",
    "        'experiment': lines[2].strip().strip('\"'),\n",
    "        'timestamp': lines[3].strip().strip('\"')\n",
    "    }\n",
    "    \n",
    "    data_start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '[all run data]' in line:\n",
    "            data_start = i\n",
    "            break\n",
    "    \n",
    "    if data_start is None:\n",
    "        raise ValueError(\"Could not find [all run data] marker\")\n",
    "    \n",
    "    params = {}\n",
    "    for i in range(7, data_start):\n",
    "        parts = lines[i].strip().split(',')\n",
    "        if parts and parts[0] and not parts[0].startswith('['):\n",
    "            param_name = parts[0].strip('\"')\n",
    "            values = [p.strip('\"') for p in parts[1:] if p.strip('\"')]\n",
    "            if not param_name.startswith('['):\n",
    "                params[param_name] = values\n",
    "    \n",
    "    header_line = lines[data_start].strip().split(',')\n",
    "    col_names = [h.strip('\"') for h in header_line]\n",
    "    \n",
    "    df = pd.read_csv(filepath, skiprows=data_start+1, header=None)\n",
    "    df.columns = col_names[:len(df.columns)]\n",
    "    \n",
    "    if df.columns[0] == '' or df.columns[0] == '[all run data]':\n",
    "        df = df.iloc[:, 1:]\n",
    "    \n",
    "    return metadata, params, df\n",
    "\n",
    "\n",
    "def reshape_runs(df):\n",
    "    cols = list(df.columns)\n",
    "    cols_per_run = 5  # v2 metrics\n",
    "    \n",
    "    runs = []\n",
    "    i = 0\n",
    "    run_id = 1\n",
    "    \n",
    "    while i < len(cols) - (cols_per_run - 1):\n",
    "        if 'step' in str(cols[i]).lower():\n",
    "            run_data = df.iloc[:, i:i+cols_per_run].copy()\n",
    "            run_data.columns = ['step', 'recovery_time', 'baseline', 'max_deviation', 'heading_variance']\n",
    "            run_data['run_id'] = run_id\n",
    "            runs.append(run_data)\n",
    "            run_id += 1\n",
    "            i += cols_per_run\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    if runs:\n",
    "        return pd.concat(runs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_conditions(params):\n",
    "    first_param = list(params.values())[0]\n",
    "    n_runs = len(first_param)\n",
    "    conditions = {}\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        cond = {'run_id': i + 1}\n",
    "        \n",
    "        if 'entrainment-mode?' in params:\n",
    "            cond['entrainment'] = params['entrainment-mode?'][i]\n",
    "            cond['mode'] = 'Entrainment' if cond['entrainment'] == 'true' else 'Coherence'\n",
    "        \n",
    "        if 'perturbation-strength' in params:\n",
    "            cond['strength'] = int(params['perturbation-strength'][i])\n",
    "        \n",
    "        if 'coupling-strength' in params:\n",
    "            cond['coupling'] = float(params['coupling-strength'][i])\n",
    "        \n",
    "        if 'identity-pull-weight' in params:\n",
    "            cond['identity_pull'] = float(params['identity-pull-weight'][i])\n",
    "        \n",
    "        conditions[i + 1] = cond\n",
    "    \n",
    "    return conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Load E003 Data (Mode Contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load E003\n",
    "e003_file = EXPORTS_DIR / 'coherence_model_simple_E003-spreadsheet.csv'\n",
    "meta, params, df_raw = parse_behaviorspace_spreadsheet(e003_file)\n",
    "df_long = reshape_runs(df_raw)\n",
    "conditions = build_conditions(params)\n",
    "\n",
    "print(f\"Experiment: {meta['experiment']}\")\n",
    "print(f\"Runs: {len(conditions)}\")\n",
    "print(\"\\nConditions:\")\n",
    "for run_id, cond in conditions.items():\n",
    "    print(f\"  Run {run_id}: {cond['mode']}, strength={cond['strength']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract final metrics for each run\n",
    "def extract_final_metrics(df_long, conditions):\n",
    "    results = []\n",
    "    for run_id, cond in conditions.items():\n",
    "        run_data = df_long[df_long['run_id'] == run_id]\n",
    "        final = run_data.iloc[-1]\n",
    "        \n",
    "        results.append({\n",
    "            'run_id': run_id,\n",
    "            'mode': cond.get('mode', 'Unknown'),\n",
    "            'strength': cond.get('strength', 0),\n",
    "            'recovery_time': final['recovery_time'],\n",
    "            'baseline': final['baseline'],\n",
    "            'max_deviation': final['max_deviation'],\n",
    "            'mean_hv': run_data['heading_variance'].mean(),\n",
    "            'std_hv': run_data['heading_variance'].std(),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "summary = extract_final_metrics(df_long, conditions)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Cost Proxy Derivation\n",
    "\n",
    "### 2.1 Shock Cost (Peak Deviation)\n",
    "> How violently does the system absorb stress?\n",
    "\n",
    "Higher max_deviation = higher instantaneous shock cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shock_cost(summary):\n",
    "    \"\"\"Shock cost = max_deviation (direct proxy)\"\"\"\n",
    "    summary = summary.copy()\n",
    "    summary['shock_cost'] = summary['max_deviation']\n",
    "    return summary\n",
    "\n",
    "summary = compute_shock_cost(summary)\n",
    "\n",
    "# Compare shock cost by mode\n",
    "coh = summary[summary['mode'] == 'Coherence'].sort_values('strength')\n",
    "ent = summary[summary['mode'] == 'Entrainment'].sort_values('strength')\n",
    "\n",
    "print(\"Shock Cost (max_deviation):\")\n",
    "print(f\"{'Strength':<10} {'Coherence':<12} {'Entrainment':<12} {'Ratio (E/C)':<12}\")\n",
    "print(\"-\" * 46)\n",
    "for (_, c), (_, e) in zip(coh.iterrows(), ent.iterrows()):\n",
    "    ratio = e['shock_cost'] / c['shock_cost'] if c['shock_cost'] > 0 else float('inf')\n",
    "    print(f\"{c['strength']:<10} {c['shock_cost']:<12.2f} {e['shock_cost']:<12.2f} {ratio:<12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 2.2 Repair Cost (Recovery Time)\n",
    "> How long does the system remain impaired?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_repair_cost(summary):\n",
    "    \"\"\"Repair cost = recovery_time (direct proxy)\n",
    "    \n",
    "    Note: -1 means Did Not Recover (DNR) - effectively infinite cost\n",
    "    For analysis, we cap at experiment duration or use a sentinel value.\n",
    "    \"\"\"\n",
    "    summary = summary.copy()\n",
    "    # Treat 0 as minimal repair cost (immediate recovery)\n",
    "    # Treat -1 as DNR (set to max observed or experiment duration)\n",
    "    max_observed = summary[summary['recovery_time'] >= 0]['recovery_time'].max()\n",
    "    summary['repair_cost'] = summary['recovery_time'].apply(\n",
    "        lambda x: max_observed * 2 if x < 0 else x  # DNR = 2x max observed\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "summary = compute_repair_cost(summary)\n",
    "\n",
    "print(\"Repair Cost (recovery_time):\")\n",
    "print(f\"{'Strength':<10} {'Coherence':<12} {'Entrainment':<12} {'Ratio (E/C)':<12}\")\n",
    "print(\"-\" * 46)\n",
    "for (_, c), (_, e) in zip(coh.iterrows(), ent.iterrows()):\n",
    "    if c['repair_cost'] == 0:\n",
    "        ratio_str = \"both 0\" if e['repair_cost'] == 0 else \"inf\"\n",
    "    else:\n",
    "        ratio_str = f\"{e['repair_cost'] / c['repair_cost']:.1f}x\"\n",
    "    print(f\"{c['strength']:<10} {c['repair_cost']:<12.0f} {e['repair_cost']:<12.0f} {ratio_str:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 2.3 Maintenance Cost (Baseline Variance)\n",
    "> How much does the system pay to stay adaptable?\n",
    "\n",
    "Higher baseline variance = ongoing regulatory effort (the \"cost of staying ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_maintenance_cost(summary):\n",
    "    \"\"\"Maintenance cost = baseline variance\n",
    "    \n",
    "    Coherence pays continuous maintenance cost (higher baseline)\n",
    "    Entrainment pays lower maintenance but higher shock/repair costs\n",
    "    \"\"\"\n",
    "    summary = summary.copy()\n",
    "    summary['maintenance_cost'] = summary['baseline']\n",
    "    return summary\n",
    "\n",
    "summary = compute_maintenance_cost(summary)\n",
    "\n",
    "print(\"Maintenance Cost (baseline variance):\")\n",
    "print(f\"{'Strength':<10} {'Coherence':<12} {'Entrainment':<12} {'Ratio (C/E)':<12}\")\n",
    "print(\"-\" * 46)\n",
    "for (_, c), (_, e) in zip(coh.iterrows(), ent.iterrows()):\n",
    "    ratio = c['maintenance_cost'] / e['maintenance_cost'] if e['maintenance_cost'] > 0 else float('inf')\n",
    "    print(f\"{c['strength']:<10} {c['maintenance_cost']:<12.1f} {e['maintenance_cost']:<12.1f} {ratio:<12.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### 2.4 Total Cost Profile\n",
    "\n",
    "Combining costs requires normalization and weighting. Key insight:\n",
    "- **Coherence**: Steady maintenance cost, low shock/repair costs\n",
    "- **Entrainment**: Low maintenance, but shock/repair costs scale superlinearly with stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_costs(summary, perturbation_frequency=1.0):\n",
    "    \"\"\"Normalize costs to [0,1] range for comparison.\n",
    "    \n",
    "    perturbation_frequency: expected perturbations per time unit\n",
    "        - Higher frequency increases weight of shock/repair costs\n",
    "        - Lower frequency favors low-maintenance strategies\n",
    "    \"\"\"\n",
    "    summary = summary.copy()\n",
    "    \n",
    "    # Normalize each cost type to [0, 1]\n",
    "    for cost_type in ['shock_cost', 'repair_cost', 'maintenance_cost']:\n",
    "        col = summary[cost_type]\n",
    "        summary[f'{cost_type}_norm'] = (col - col.min()) / (col.max() - col.min() + 1e-10)\n",
    "    \n",
    "    # Composite cost:\n",
    "    # - Maintenance is continuous (weight = 1)\n",
    "    # - Shock/repair are episodic (weight = perturbation_frequency)\n",
    "    summary['episodic_cost_norm'] = (\n",
    "        summary['shock_cost_norm'] + summary['repair_cost_norm']\n",
    "    ) / 2\n",
    "    \n",
    "    summary['total_cost'] = (\n",
    "        summary['maintenance_cost_norm'] + \n",
    "        perturbation_frequency * summary['episodic_cost_norm']\n",
    "    )\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Compare at different perturbation frequencies\n",
    "for freq in [0.5, 1.0, 2.0]:\n",
    "    summary_norm = normalize_costs(summary, perturbation_frequency=freq)\n",
    "    \n",
    "    print(f\"\\nTotal Cost (perturbation frequency = {freq}):\")\n",
    "    print(f\"{'Strength':<10} {'Coherence':<12} {'Entrainment':<12} {'Lower Cost':<12}\")\n",
    "    print(\"-\" * 46)\n",
    "    \n",
    "    coh_n = summary_norm[summary_norm['mode'] == 'Coherence'].sort_values('strength')\n",
    "    ent_n = summary_norm[summary_norm['mode'] == 'Entrainment'].sort_values('strength')\n",
    "    \n",
    "    for (_, c), (_, e) in zip(coh_n.iterrows(), ent_n.iterrows()):\n",
    "        winner = 'Coherence' if c['total_cost'] < e['total_cost'] else 'Entrainment'\n",
    "        print(f\"{c['strength']:<10} {c['total_cost']:<12.3f} {e['total_cost']:<12.3f} {winner:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 3. Cost Profile Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_profiles(summary):\n",
    "    \"\"\"Visualize cost profiles by regime.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    strengths = sorted(summary['strength'].unique())\n",
    "    x = np.arange(len(strengths))\n",
    "    width = 0.35\n",
    "    \n",
    "    coh = summary[summary['mode'] == 'Coherence'].sort_values('strength')\n",
    "    ent = summary[summary['mode'] == 'Entrainment'].sort_values('strength')\n",
    "    \n",
    "    # 1. Shock Cost\n",
    "    ax = axes[0, 0]\n",
    "    ax.bar(x - width/2, coh['shock_cost'], width, label='Coherence', color='#3498db', alpha=0.8)\n",
    "    ax.bar(x + width/2, ent['shock_cost'], width, label='Entrainment', color='#e74c3c', alpha=0.8)\n",
    "    ax.set_ylabel('Shock Cost (max deviation)')\n",
    "    ax.set_title('Shock Cost\\n(instantaneous perturbation load)', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(strengths)\n",
    "    ax.set_xlabel('Perturbation Strength')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Repair Cost\n",
    "    ax = axes[0, 1]\n",
    "    ax.bar(x - width/2, coh['repair_cost'], width, label='Coherence', color='#3498db', alpha=0.8)\n",
    "    ax.bar(x + width/2, ent['repair_cost'], width, label='Entrainment', color='#e74c3c', alpha=0.8)\n",
    "    ax.set_ylabel('Repair Cost (recovery time)')\n",
    "    ax.set_title('Repair Cost\\n(time to restore viability)', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(strengths)\n",
    "    ax.set_xlabel('Perturbation Strength')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. Maintenance Cost\n",
    "    ax = axes[1, 0]\n",
    "    ax.bar(x - width/2, coh['maintenance_cost'], width, label='Coherence', color='#3498db', alpha=0.8)\n",
    "    ax.bar(x + width/2, ent['maintenance_cost'], width, label='Entrainment', color='#e74c3c', alpha=0.8)\n",
    "    ax.set_ylabel('Maintenance Cost (baseline variance)')\n",
    "    ax.set_title('Maintenance Cost\\n(ongoing regulatory effort)', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(strengths)\n",
    "    ax.set_xlabel('Perturbation Strength')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Cost Tradeoff Summary\n",
    "    ax = axes[1, 1]\n",
    "    \n",
    "    # Calculate ratios\n",
    "    shock_ratio = ent['shock_cost'].values / (coh['shock_cost'].values + 1e-10)\n",
    "    repair_ratio = ent['repair_cost'].values / (coh['repair_cost'].values + 1e-10)\n",
    "    # For repair, handle 0/0 case\n",
    "    repair_ratio = np.where(\n",
    "        (coh['repair_cost'].values == 0) & (ent['repair_cost'].values == 0),\n",
    "        1.0,\n",
    "        np.where(coh['repair_cost'].values == 0, 10.0, repair_ratio)\n",
    "    )\n",
    "    maint_ratio = coh['maintenance_cost'].values / (ent['maintenance_cost'].values + 1e-10)\n",
    "    \n",
    "    ax.plot(strengths, shock_ratio, 'o-', label='Shock (Ent/Coh)', color='#e74c3c', linewidth=2)\n",
    "    ax.plot(strengths, repair_ratio, 's-', label='Repair (Ent/Coh)', color='#9b59b6', linewidth=2)\n",
    "    ax.plot(strengths, maint_ratio, '^-', label='Maintenance (Coh/Ent)', color='#3498db', linewidth=2)\n",
    "    ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='Parity')\n",
    "    \n",
    "    ax.set_ylabel('Cost Ratio')\n",
    "    ax.set_title('Cost Tradeoff Ratios\\n(>1 means first regime pays more)', fontweight='bold')\n",
    "    ax.set_xlabel('Perturbation Strength')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.5, 20)\n",
    "    \n",
    "    plt.suptitle('E003: Cost Profiles by Regime', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "fig, axes = plot_cost_profiles(summary)\n",
    "plt.savefig(EXPORTS_DIR / 'cost_profiles_E003.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 4. Cost Distribution Over Time\n",
    "\n",
    "Key insight from `cost-types.md`:\n",
    "> Coherence: steady, bounded cost over time  \n",
    "> Entrainment: minimal cost during calm, large spikes during perturbation and recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temporal_cost_distribution(df_long, conditions, strength_filter=80):\n",
    "    \"\"\"Plot variance (proxy for instantaneous cost) over time.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    \n",
    "    for run_id, cond in conditions.items():\n",
    "        if cond['strength'] != strength_filter:\n",
    "            continue\n",
    "        \n",
    "        run_data = df_long[df_long['run_id'] == run_id]\n",
    "        \n",
    "        color = '#3498db' if cond['mode'] == 'Coherence' else '#e74c3c'\n",
    "        linestyle = '-' if cond['mode'] == 'Coherence' else '--'\n",
    "        \n",
    "        ax.plot(run_data['step'], run_data['heading_variance'], \n",
    "                color=color, linestyle=linestyle, linewidth=1.5,\n",
    "                label=f\"{cond['mode']}\")\n",
    "    \n",
    "    # Mark perturbation window (tick 300-330 based on experiment design)\n",
    "    ax.axvspan(300, 330, alpha=0.2, color='orange', label='Perturbation')\n",
    "    \n",
    "    ax.set_xlabel('Time (ticks)')\n",
    "    ax.set_ylabel('Heading Variance (instantaneous cost proxy)')\n",
    "    ax.set_title(f'Temporal Cost Distribution (Perturbation Strength = {strength_filter})', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_temporal_cost_distribution(df_long, conditions, strength_filter=80)\n",
    "plt.savefig(EXPORTS_DIR / 'temporal_cost_E003_str80.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_cost_stats(df_long, conditions):\n",
    "    \"\"\"Compute temporal cost distribution statistics.\n",
    "    \n",
    "    For each run, calculate:\n",
    "    - Pre-perturbation variance (baseline cost)\n",
    "    - During-perturbation variance (acute cost)\n",
    "    - Post-perturbation variance until recovery (repair cost)\n",
    "    \"\"\"\n",
    "    # Perturbation window: 300-330 (from experiment design)\n",
    "    PERTURB_START = 300\n",
    "    PERTURB_END = 330\n",
    "    \n",
    "    results = []\n",
    "    for run_id, cond in conditions.items():\n",
    "        run_data = df_long[df_long['run_id'] == run_id]\n",
    "        \n",
    "        pre = run_data[run_data['step'] < PERTURB_START]['heading_variance']\n",
    "        during = run_data[(run_data['step'] >= PERTURB_START) & (run_data['step'] <= PERTURB_END)]['heading_variance']\n",
    "        post = run_data[run_data['step'] > PERTURB_END]['heading_variance']\n",
    "        \n",
    "        results.append({\n",
    "            'run_id': run_id,\n",
    "            'mode': cond['mode'],\n",
    "            'strength': cond['strength'],\n",
    "            'pre_mean': pre.mean(),\n",
    "            'pre_std': pre.std(),\n",
    "            'during_mean': during.mean(),\n",
    "            'during_max': during.max(),\n",
    "            'post_mean': post.mean(),\n",
    "            'post_std': post.std(),\n",
    "            'acute_spike': during.max() - pre.mean(),  # How much cost spiked\n",
    "            'recovery_burden': (post.mean() - pre.mean()) * len(post),  # Integrated excess cost\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "temporal_stats = compute_temporal_cost_stats(df_long, conditions)\n",
    "print(temporal_stats[['mode', 'strength', 'pre_mean', 'acute_spike', 'recovery_burden']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 5. Crossover Analysis\n",
    "\n",
    "At what perturbation frequency does coherence become cost-advantageous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crossover_frequency(summary, strength):\n",
    "    \"\"\"Find the perturbation frequency at which coherence becomes preferable.\n",
    "    \n",
    "    At low frequency: entrainment wins (lower maintenance cost dominates)\n",
    "    At high frequency: coherence wins (lower shock/repair costs dominate)\n",
    "    \"\"\"\n",
    "    coh = summary[(summary['mode'] == 'Coherence') & (summary['strength'] == strength)].iloc[0]\n",
    "    ent = summary[(summary['mode'] == 'Entrainment') & (summary['strength'] == strength)].iloc[0]\n",
    "    \n",
    "    # Maintenance cost: coherence pays more (continuous)\n",
    "    maint_diff = coh['maintenance_cost'] - ent['maintenance_cost']\n",
    "    \n",
    "    # Episodic cost: entrainment pays more (per perturbation)\n",
    "    episodic_coh = coh['shock_cost'] + coh['repair_cost']\n",
    "    episodic_ent = ent['shock_cost'] + ent['repair_cost']\n",
    "    episodic_diff = episodic_ent - episodic_coh\n",
    "    \n",
    "    if episodic_diff <= 0:\n",
    "        return float('inf')  # Entrainment always wins\n",
    "    \n",
    "    # Crossover: maint_diff = freq * episodic_diff\n",
    "    # freq = maint_diff / episodic_diff\n",
    "    crossover_freq = maint_diff / episodic_diff if episodic_diff > 0 else 0\n",
    "    \n",
    "    return crossover_freq\n",
    "\n",
    "print(\"Crossover Frequency Analysis:\")\n",
    "print(\"(Perturbations per maintenance-cost-unit where coherence becomes preferable)\")\n",
    "print()\n",
    "print(f\"{'Strength':<12} {'Crossover Freq':<15} {'Interpretation':<30}\")\n",
    "print(\"-\" * 57)\n",
    "for strength in sorted(summary['strength'].unique()):\n",
    "    freq = find_crossover_frequency(summary, strength)\n",
    "    if freq == float('inf'):\n",
    "        interp = \"Entrainment always preferable\"\n",
    "    elif freq <= 0:\n",
    "        interp = \"Coherence always preferable\"\n",
    "    elif freq < 1:\n",
    "        interp = \"Coherence preferable (low freq threshold)\"\n",
    "    else:\n",
    "        interp = f\"Coherence preferable above {freq:.2f}/unit\"\n",
    "    print(f\"{strength:<12} {freq:<15.3f} {interp:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 6. Summary: Cost Profiles by Regime\n",
    "\n",
    "### Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cost_summary(summary):\n",
    "    \"\"\"Print formatted cost summary.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"COST DERIVATION SUMMARY (E003)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    coh = summary[summary['mode'] == 'Coherence'].sort_values('strength')\n",
    "    ent = summary[summary['mode'] == 'Entrainment'].sort_values('strength')\n",
    "    \n",
    "    print(\"\\n### COHERENCE REGIME\")\n",
    "    print(\"Cost profile: Continuous, bounded\")\n",
    "    print(f\"  Maintenance cost (baseline): {coh['maintenance_cost'].mean():.1f} (range: {coh['maintenance_cost'].min():.1f}-{coh['maintenance_cost'].max():.1f})\")\n",
    "    print(f\"  Shock cost scaling: Linear ({coh['shock_cost'].min():.1f} -> {coh['shock_cost'].max():.1f})\")\n",
    "    print(f\"  Repair cost scaling: Minimal ({coh['repair_cost'].min():.0f} -> {coh['repair_cost'].max():.0f} ticks)\")\n",
    "    \n",
    "    print(\"\\n### ENTRAINMENT REGIME\")\n",
    "    print(\"Cost profile: Episodic, unbounded\")\n",
    "    print(f\"  Maintenance cost (baseline): {ent['maintenance_cost'].mean():.1f} (range: {ent['maintenance_cost'].min():.1f}-{ent['maintenance_cost'].max():.1f})\")\n",
    "    print(f\"  Shock cost scaling: Superlinear ({ent['shock_cost'].min():.1f} -> {ent['shock_cost'].max():.1f})\")\n",
    "    print(f\"  Repair cost scaling: Superlinear ({ent['repair_cost'].min():.0f} -> {ent['repair_cost'].max():.0f} ticks)\")\n",
    "    \n",
    "    print(\"\\n### CRITICAL THRESHOLD\")\n",
    "    # Find where entrainment's episodic costs exceed coherence's maintenance advantage\n",
    "    threshold_idx = None\n",
    "    for i, (strength, c_shock, c_repair, e_shock, e_repair) in enumerate(zip(\n",
    "        coh['strength'].values, coh['shock_cost'].values, coh['repair_cost'].values,\n",
    "        ent['shock_cost'].values, ent['repair_cost'].values\n",
    "    )):\n",
    "        shock_ratio = e_shock / c_shock if c_shock > 0 else float('inf')\n",
    "        if shock_ratio > 2:  # Entrainment shock cost > 2x coherence\n",
    "            threshold_idx = i\n",
    "            print(f\"  Threshold between strength {coh['strength'].values[max(0,i-1)]} and {strength}\")\n",
    "            print(f\"  At strength {strength}: Entrainment shock = {shock_ratio:.1f}x Coherence\")\n",
    "            break\n",
    "    \n",
    "    if threshold_idx is None:\n",
    "        print(\"  No clear threshold detected in tested range\")\n",
    "    \n",
    "    print(\"\\n### INTERPRETATION\")\n",
    "    print(\"  Coherence: 'Pay as you go' - steady regulatory cost, bounded response\")\n",
    "    print(\"  Entrainment: 'Pay when stressed' - low baseline, catastrophic under high stress\")\n",
    "    print(\"\\n  Optimal regime depends on:\")\n",
    "    print(\"    1. Environmental volatility (perturbation frequency)\")\n",
    "    print(\"    2. Perturbation magnitude distribution\")\n",
    "    print(\"    3. Available capacity buffer\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "print_cost_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary with cost columns\n",
    "summary.to_csv(EXPORTS_DIR / 'cost_derivation_E003.csv', index=False)\n",
    "temporal_stats.to_csv(EXPORTS_DIR / 'temporal_cost_stats_E003.csv', index=False)\n",
    "\n",
    "print(\"Exported:\")\n",
    "print(f\"  - {EXPORTS_DIR / 'cost_derivation_E003.csv'}\")\n",
    "print(f\"  - {EXPORTS_DIR / 'temporal_cost_stats_E003.csv'}\")\n",
    "print(f\"  - {EXPORTS_DIR / 'cost_profiles_E003.png'}\")\n",
    "print(f\"  - {EXPORTS_DIR / 'temporal_cost_E003_str80.png'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
